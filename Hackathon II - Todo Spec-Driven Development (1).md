# Hackathon II

# The Evolution of Todo – Mastering Spec-Driven Development & Cloud Native AI

The future of software development is AI-native and spec-driven. As AI agents like Claude Code become more powerful, the role of the engineer shifts from "syntax writer" to "system architect." We have already explored Spec-Driven Book Authoring. Now, we want you to master the Architecture of Intelligence.

In this hackathon, you will master the art of building applications iteratively—starting from a simple console app and evolving it into a fully-featured, cloud-native AI chatbot deployed on Kubernetes. This journey will teach you the Nine Pillars of AI-Driven Development, Claude Code, Spec-Driven Development with Reusable Intelligence and Cloud-Native AI technologies through hands-on implementation.

# Excel in the Hackathon and Launch Your Journey as an AI Startup Founder

We've recently launched Panaversity (panavenistry.org), an initiative focused on teaching cutting-edge AI courses. If you perform well in this hackathon, you may be invited for an interview to join the Panavenity core team and potentially step into the role of a startup founder within this growing ecosystem. You will get a chance to work with Panavenity founders Zia, Rehan, Junaid, and Wania and become the very best. You may also get a chance to teach at Panavenity, PIAIC, and GIAIC.

# What You Will Learn

- Spec-Driven Development using Claude Code and Spec-Kit Plus  
Reusable Intelligence: Agents Skills and Subagent Development  
Full-Stack Development with Next.js, FastAPI, SQLModel, and Neon Serverless Database  
AI Agent Development using OpenAI Agents SDK and Official MCP SDK  
Cloud-Native Deployment with Docker, Kubernetes, Minikube, and Helm Charts  
Event-Driven Architecture using Kafka and Dapr  
- AIOps with kubectl-ai, kagent and Claude Code  
- Develop Cloud-Native Blueprints for Spec-Driven Deployment

# Research Note: Deployment Blueprints for Spec-Driven Deployment

1. Is Spec-Driven Development Key for Infrastructure Automation?  
2. ChatGPT Progressive Learning Conversation  
3. Spec-Driven Cloud-Native Architecture: Governing AI Agents for Managed Services with Claude Code and SpecKit

# Requirements

You are required to complete the 5-Phase "Evolution of Todo" Project using Claude Code and Spec-Kit Plus. The core deliverables are:

- Spec-Driven Implementation: You must implement all 5 Phases of the project (detailed below). You are strictly required to use Spec-Driven Development. You

must write a Markdown Constitution and Spec for every feature of the phase, and use Claude Code to generate the implementation.

Constraint: You cannot write the code manually. You must refine the Spec until Claude Code generates the correct output.

- Integrated AI Chatbot: In Phases III, IV, and V, you must implement a conversational interface using OpenAI Chatkit, OpenAI Agents SDK, and Official MCP SDK. The bot must be able to manage the user's Todo list via natural language (e.g., "Reschedule my morning meetings to 2 PM").  
- Cloud Native Deployment: In Phases IV and V, you must deploy the chatbot locally on Minikube, and on the cloud on DigitalOcean Kubernetes (DOKS).

# Todo App Feature Progression

# Basic Level (Core Essentials)

These form the foundation—quick to build, essential for any MVP:

1. Add Task – Create new todo items  
2. Delete Task - Remove tasks from the list  
3. Update Task - Modify existing task details  
4. View Task List - Display all tasks  
5. Mark as Complete - Toggle task completion status

# Intermediate Level (Organization & Usability)

Add these to make the app feel polished and practical:

1.  
2. Priorities & Tags/Categories – Assign levels (high/medium/low) or labels (work/home)  
3. Search & Filter - Search by keyword; filter by status, priority, or date  
4. Sort Tasks – Reorder by due date, priority, or alphabetically

# Advanced Level (Intelligent Features)

1. Recurring Tasks – Auto-reschedule repeating tasks (e.g., "weekly meeting")  
2. Due Dates & Time Reminders - Set deadlines with date/time pickers; browser notifications

Hackathon Phases Overview  

<table><tr><td>Phase</td><td>Description</td><td>Technology Stack</td><td>Points</td><td>Due Date</td></tr><tr><td>Phase I</td><td>In-Memory Python Console App</td><td>Python, Claude Code, Spec-Kit Plus</td><td>100</td><td>Dec 7, 2025</td></tr><tr><td>Phase II</td><td>Full-Stack Web Application</td><td>Next.js, FastAPI, SQLModel, Neon DB</td><td>150</td><td>Dec 14, 2025</td></tr><tr><td>Phase III</td><td>AI-Powered Todo Chatbot</td><td>OpenAI ChatKit, Agents SDK, Official MCP SDK</td><td>200</td><td>Dec 21, 2025</td></tr><tr><td>Phase IV</td><td>Local Kubernetes Deployment</td><td>Docker, Minikube, Helm, kubectl-ai, kagent</td><td>250</td><td>Jan 4, 2026</td></tr><tr><td>Phase V</td><td>Advanced Cloud Deployment</td><td>Kafka, Dapr, DigitalOcean DOKS</td><td>300</td><td>Jan 18, 2026</td></tr><tr><td>TOTAL</td><td></td><td></td><td>1,000</td><td></td></tr></table>

# Bonus Points

Participants can earn additional bonus points for exceptional implementations:

<table><tr><td>Bonus Feature</td><td>Points</td></tr><tr><td>Reusable Intelligence – Create and use reusable intelligence via Claude Code Subagents and Agent Skills</td><td>+200</td></tr><tr><td>Create and use Cloud-Native Blueprints via Agent Skills</td><td>+200</td></tr><tr><td>Multi-language Support – Support Urdu in chatbot</td><td>+100</td></tr><tr><td>Voice Commands – Add voice input for todo commands</td><td>+200</td></tr><tr><td>TOTAL BONUS</td><td>+600</td></tr></table>

# Timeline

- Submission Deadline: On Sundays on dates as mentioned above.  
Live Presentations: On Sundays, December 7, 14, and 21, 2025 and on January 4 and 18, 2026 starting at 8:00 PM on Zoom. Final Live Presentation date to be determined.

Top submissions will be invited via WhatsApp to present live on Zoom.

Note: All submissions will be evaluated. Live presentation is by invitation only, but does not affect final scoring.

<table><tr><td>Milestone</td><td>Date</td><td>Description</td></tr><tr><td>Hackathon Start</td><td>Monday, Dec 1, 2025</td><td>Documentation released</td></tr><tr><td>Phase I Due</td><td>Sunday, Dec 7, 2025</td><td>Console app checkpoint</td></tr><tr><td>Phase II Due</td><td>Sunday, Dec 14, 2025</td><td>Web app checkpoint</td></tr><tr><td>Phase III Due</td><td>Sunday, Dec 21, 2025</td><td>Chatbot checkpoint</td></tr><tr><td>Phase IV Due</td><td>Sunday, Jan 4, 2026</td><td>Local K8s checkpoint</td></tr><tr><td>Final Submission</td><td>Sunday, Jan 18, 2026</td><td>All phases complete</td></tr><tr><td>Live Presentations</td><td>Sundays, Dec 7, 14, 21, and Jan 4 and 18</td><td>Top submissions present</td></tr></table>

# Submit and Present Your Project:

Once you have completed the project you will submit your project here at each phase:

https://forms.gle/CQsSEGM3GeCrL43c8

# Submit the following via the form for each phase (You can submit a phase before the due date):

1. Public GitHub Repo Link  
2. Published App Link for Vercel.  
3. Include a demo video link (must be under 90 seconds). Judges will only watch the first 90 seconds. You can use NotebookLM or record your demo.  
4. WhatsApp number (top submissions will be invited to present live)

Everyone is welcome to join the Zoom meeting to watch the presentations. Only invited participants will present their submissions. The meetings start at 8:00 PM on Sundays.

# Join Zoom Meeting

- Time: 08:00 PM On Sundays, December 7, 14, and 21, 2025 and on January 4, 2026 starting at 8:00 PM on Zoom. Final Live Presentation date to be determined.  
- https://us06webzoom.us/j/84976847088?pwd=Z7t7NaeXwVmmR5fysCv7NiMbfbhld a.1  
- Meeting ID: 849 7684 7088  
Passcode: 305850

# Project Details: The Evolution of Todo

Focus and Theme: From CLI to Distributed Cloud-Native AI Systems.

Goal: Students act as Product Architects, using AI to build progressively complex software without writing boilerplate code.

# Project Overview

This project simulates the real-world evolution of software. You will start with a simple script and end with a Kubernetes-managed, event-driven, AI-powered distributed system.

# Phase Breakdown

# Phase I:Todo In-Memory Python Console App

Basic Level Functionality

Objective: Build a command-line todo application that stores tasks in memory using Claude Code and Spec-Kit Plus.

# Requirements

- Implement all 5 Basic Level features (Add, Delete, Update, View, Mark Complete)  
- Use spec-driven development with Claude Code and Spec-Kit Plus  
- Follow clean code principles and proper Python project structure

# Technology Stack

UV  
- Python 3.13+  
Claude Code  
- GitHub Spec-Kit

# Deliverables

1. GitHub repository with:

- Constitution file  
- specs history folder containing all specification files  
- /src folder with Python source code  
- README.md with setup instructions  
CLAUDE.md with Claude Code instructions

2. Working console application demonstrating:

- Adding tasks with title and description  
Listing all tasks with status indicators  
- Updating task details  
- Deleting tasks by ID  
- Marking tasks as complete/incomplete

# Windows Users: WSL 2 Setup

Windows users must use WSL 2 (Windows Subsystem for Linux) for development:

```shell
Install WSL 2  
wsl --install  
# Set WSL 2 as default  
wsl --set-default-version 2  
# Install Ubuntu  
wsl --install -d Ubuntu-22.04
```

# Phase II:Todo Full-Stack Web Application

Basic Level Functionality

Objective: Using Claude Code and Spec-Kit Plus transform the console app into a modern multi-user web application with persistent storage.

# Requirements

- Implement all 5 Basic Level features as a web application  
Create RESTful API endpoints  
Build responsive frontend interface  
- Store data in Neon Serverless PostgreSQL database  
Authentication - Implement user signup/signin using Better Auth

# Technology Stack

<table><tr><td>Layer</td><td>Technology</td></tr><tr><td>Frontend</td><td>Next.js 16+ (App Router)</td></tr><tr><td>Backend</td><td>Python FastAPI</td></tr><tr><td>ORM</td><td>SQLModel</td></tr><tr><td>Database</td><td>Neon Serverless PostgreSQL</td></tr><tr><td>Spec-Driven</td><td>Claude Code + Spec-Kit Plus</td></tr><tr><td>Authentication</td><td>Better Auth</td></tr></table>

# API Endpoints

<table><tr><td>Method</td><td>Endpoint</td><td>Description</td></tr><tr><td>GET</td><td>/api/{user_id}/tasks</td><td>List all tasks</td></tr><tr><td>POST</td><td>/api/{user_id}/tasks</td><td>Create a new task</td></tr><tr><td>GET</td><td>/api/{user_id}/tasks/{id}</td><td>Get task details</td></tr><tr><td>PUT</td><td>/api/{user_id}/tasks/{id}</td><td>Update a task</td></tr><tr><td>DELETE</td><td>/api/{user_id}/tasks/{id}</td><td>Delete a task</td></tr><tr><td>PATCH</td><td>/api/{user_id}/tasks/{id}/complete</td><td>Toggle completion</td></tr></table>

# Securing the REST API

Better Auth + FastAPI Integration

# The Challenge

Better Auth is a JavaScript/TypeScript authentication library that runs on your Next.js frontend. However, your FastAPI backend is a separate Python service that needs to verify which user is making API requests.

# The Solution: JWT Tokens

Better Auth can be configured to issue JWT (JSON Web Token) tokens when users log in. These tokens are self-contained credentials that include user information and can be verified by any service that knows the secret key.

# How It Works

- User logs in on Frontend  $\rightarrow$  Better Auth creates a session and issues a JWT token  
- Frontend makes API call  $\rightarrow$  Includes the JWT token in the Authorization: Bearer <token> header  
- Backend receives request  $\rightarrow$  Extracts token from header, verifies signature using shared secret  
- Backend identifies user  $\rightarrow$  Decodes token to get user ID, email, etc. and matches it with the user ID in the URL  
- Backend filters data  $\rightarrow$  Returns only tasks belonging to that user

# What Needs to Change

<table><tr><td>Component</td><td>Changes Required</td></tr><tr><td>Better Auth Config</td><td>Enable JWT plugin to issue tokens</td></tr><tr><td>Frontend API Client</td><td>Attach JWT token to every API request header</td></tr><tr><td>FastAPI Backend</td><td>Add middleware to verify JWT and extract user</td></tr><tr><td>API Routes</td><td>Filter all queries by the authenticated user&#x27;s ID</td></tr></table>

# The Shared Secret

Both frontend (Better Auth) and backend (FastAPI) must use the same secret key for JWT signing and verification. This is typically set via environment variable BETTER_AUTH_secret in both services.

# Security Benefits

<table><tr><td>Benefit</td><td>Description</td></tr><tr><td>User Isolation</td><td>Each user only sees their own tasks</td></tr><tr><td>Stateless Auth</td><td>Backend doesn&#x27;t need to call frontend to verify users</td></tr><tr><td>Token Expiry</td><td>JWTs expire automatically (e.g., after 7 days)</td></tr><tr><td>No Shared DB Session</td><td>Frontend and backend can verify auth independently</td></tr></table>

# API Behavior Change

# After Auth:

<table><tr><td>All endpoints require valid JWT token</td></tr><tr><td>Requests without token receive 401 Unauthorized</td></tr><tr><td>Each user only sees/modifies their own tasks</td></tr><tr><td>Task ownership is enforced on every operation</td></tr></table>

# Bottom Line

The REST API endpoints stay the same (GET /api/user_id/tasks, POST /api/user_id/tasks, etc.), but every request now must include a JWT token, and all responses are filtered to only include that user's data.

# Monorepo Organization For Full-Stack Projects With GitHub Spec-Kit + Claude Code

This guide explains how to organize your Full-Stack Projects in a monorepo to integrate GitHub Spec-Kit for spec-driven development with Claude Code. This guide explains how to organize your repository so that Claude Code and Spec-Kit Plus can effectively edit both frontend (Next.js) and backend (FastAPI) code in a single context.

# Spec-Kit Monorepo Folder Structure

```txt
hackathon-todo/ .spec-kit/ # Spec-Kit configuration config.yaml specs/ # Spec-Kit managed specifications overview.md # Project overview architecture.md # System architecture features/ # Feature specifications task-crud.md chatbot.md api/ # API specifications rest-endpoints.md mcp-tools.md database/ # Database specifications schema.md ui/ # UI specifications components.md pages.md CLAUDE.md # Root Claude Code instructions frontend/ CLAUDE.md ... (Next.js app) backend/ CLAUDE.md ... (FastAPI app) docker-compose.yml README.md
```

# Key Differences from Basic Monorepo

<table><tr><td>Aspect</td><td>Without Spec-Kit</td><td>With Spec-Kit</td></tr><tr><td>Specs Location</td><td>/specs (flat)</td><td>/specs (organized by type)</td></tr><tr><td>Config File</td><td>None</td><td>/.spec-kit/config.yaml</td></tr><tr><td>Spec Format</td><td>Freeform markdown</td><td>Spec-Kit conventions</td></tr><tr><td>Referencing</td><td>@specs/file.md</td><td>@specs/features/file.md</td></tr></table>

# Spec-Kit Config File

```yaml
# .spec-kit/config.yaml
name: hackathon-todo
version: "1.0"
structure:
  specs_dir: specs
  features_dir: specs/features
  api_dir: specs/api
  database_dir: specs/database
  ui_dir: specs/ui
phases:
```

```yaml
- name: phase1 console  
features: [task-crud]  
- name: phase2-web  
features: [task-crud, authentication]  
- name: phase3-chatbot  
features: [task-crud, authentication, chatbot]
```

# CLAUDE.md Files

Create multiple CLAUDE.md files to provide context at different levels:

# Root CLAUDE.md

```markdown
#Todo App - Hackathon II   
## Project Overview   
This is a monorepo using GitHub Spec-Kit for spec-driven development.   
## Spec-Kit Structure   
Specifications are organized in /specs:   
-/specs/overview.md - Project overview   
-/specs/features/ - Feature specs (what to build)   
-/specs/api/ - API endpoint and MCP tool specs   
-/specs/database/ - Schema and model specs   
-/specs/pi/ - Component and page specs   
## How to Use Specs   
1. Always read relevant spec before implementing   
2. Reference specs with: @specs/features/task-crud.md   
3. Update specs if requirements change   
## Project Structure   
-/frontend - Next.js 14 app   
-/frontend - Python FastAPI server   
## Development Workflow   
1. Read spec: @specs/features/[feature].md   
2. Implement backend: @frontend/CLAUDE.md   
3. Implement frontend: @frontend/CLAUDE.md   
4. Test and iterate   
## Commands   
- Frontend: cd frontend && npm run dev   
- Backend: cd backend && uvmicorn main:app --reload   
- Both: docker-compose up
```

# Frontend CLAUDE.md

```markdown
# Frontend Guidelines
## Stack
- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
## Patterns
- Use server components by default
- Client components only when needed (interactivity)
- API calls go through `/lib/api.ts`
## Component Structure
- `components` - Reusable UI components
- `app` - Pages and layouts
## API Client
All backend calls should use the api client:
import { api } from '@lib/api'
const tasks = await api.getTasks()
## Styling
- Use Tailwind CSS classes
```

```txt
- No inline styles
- Follow existing component patterns
```

Backend CLAUDE.md  
```markdown
#Backend Guidelines
## Stack
- FastAPI
- SQLModel (ORM)
- Neon PostgreSQL
## Project Structure
- `main.py` - FastAPI app entry point
- `models.py` - SQLModel database models
- `routes/` - API route handlers
- `db.py` - Database connection
## API Conventions
- All routes under `/api/`
- Return JSON responses
- Use Pydantic models for request/response
- Handle errors with exception
## Database
- Use SQLModel for all database operations
- Connection string from environment variable: DATABASE_URL
## Running
uvicorn main:app --reload --port 8000
```

# Example Spec Files

/specs/overview.md  
```txt
#Todo App Overview   
##Purpose   
A todo application that evolves from console app to AI chatbot.   
##Current Phase   
Phase II: Full-Stack Web Application   
#Tech Stack   
-Frontend: Next.js 14, TypeScript, Tailwind CSS   
-Backend: FastAPI, SQLModel, Neon PostgreSQL   
-Auth: Better Auth with JWT   
#Features   
-[] Task CRUD operations   
-[] User authentication   
-[] Task filtering and sorting
```

/specs/features/task-crud.md  
```txt
Feature: Task CRUD Operations
```

Acceptance Criteria  
```markdown
## User Stories
- As a user, I can create a new task
- As a user, I can view all my tasks
- As a user, I can update a task
- As a user, I can delete a task
- As a user, I can mark a task complete
```

```markdown
##Create Task
-Title is required (1-200 characters)
-Description is optional (max 1000 characters)
-Task is associated with logged-in user
##View Tasks
-Only show tasks for current user
-Display title, status, created date
-Support filtering by status
```

/specs/api/rest-endpoints.md  
```markdown
# REST API Endpoints
## Base URL
- Development: http://localhost:8000
- Production: https://api.example.com
## Authentication
All endpoints require JWT token in header:
Authorization: Bearer <token>
## Endpoints
## GET /api/tasks
List all tasks for authenticated user.
Query Parameters:
- status: "all" | "pending" | "completed"
- sort: "created" | "title" | "due_date"
Response: Array of Task objects
## POST /api/tasks
Create a new task.
Request Body:
- title: string (required)
- description: string (optional)
Response: Created Task object
```

/specs/database/schema.md  
```markdown
# Database Schema
## Tables
## # users (managed by Better Auth)
- id: string (primary key)
- email: string (unique)
- name: string
- created_at: timestamp
## # tasks
- id: integer (primary key)
- user_id: string (foreign key -> users.id)
- title: string (not null)
- description: text (nullable)
- completed: boolean (default false)
- created_at: timestamp
- updated_at: timestamp
## Indexes
- tasks.user_id (for filtering by user)
- taskscompleted (for status filtering)
```

# Workflow with Spec-Kit + Claude Code

Write/Update Spec  $\rightarrow$  @specs/features/new-feature.md  
- Ask Claude Code to Implement  $\rightarrow$  "Implement @specs/features/new-feature.md"  
- Claude Code reads: Root CLAUDE.md, Feature spec, API spec, Database spec, Relevant CLAUDE.md  
- Claude Code implements in both frontend and backend  
- Test and iterate on spec if needed

# Referencing Specs in Claude Code

```txt
# Implement a feature  
You: @specs/features/task-crud.md implement the create task feature  
# Implement API  
You: @specs/api/rest-endpoints.md implement the GET /api/tasks endpoint  
# Update database  
You: @specs/database-schema.md add due_date field to tasks  
# Full feature across stack  
You: @specs/features/authentication.md implement Better Auth login
```

# Summary

<table><tr><td>Component</td><td>Purpose</td></tr><tr><td>/.spec-kit config.yaml</td><td>Spec-Kit configuration</td></tr><tr><td>/specs/overview.md</td><td>Project overview and status</td></tr><tr><td>/specs/features/</td><td>What to build (user stories, acceptance criteria)</td></tr><tr><td>/specs/api/</td><td>How APIs should work</td></tr><tr><td>/specs/database/</td><td>Data models and schema</td></tr><tr><td>/specs/pii/</td><td>UI components and pages</td></tr><tr><td>/CLAUDE.md</td><td>How to navigate and use specs</td></tr><tr><td>/frontend/CLAUDE.md</td><td>Frontend-specific patterns</td></tr><tr><td>FFT/core/CLAUDE.md</td><td>Backend-specific patterns</td></tr></table>

# Key Point:

Spec-Kit provides organized, structured specs that Claude Code can reference. The CLAUDE.md files tell Claude Code how to use those specs and project-specific conventions.

# Summary: Monorepo vs Separate Repos

<table><tr><td>Approach</td><td>Pros</td><td>Cons</td></tr><tr><td>Monorepo ★</td><td>Single CLAUGE.md context, easier cross-cutting changes</td><td>Larger repo</td></tr><tr><td>Separate Repos</td><td>Clear separation, independent deployments</td><td>Claude Code needs workspace setup</td></tr></table>

# Recommendation:

Use monorepo for the hackathon – simpler for Claude Code to navigate and edit both frontend and backend in a single context.

Key Benefits of This Structure  

<table><tr><td>Benefit</td><td>Description</td></tr><tr><td>Single Context</td><td>Claude Code sees entire project, can make cross-cutting changes</td></tr><tr><td>Layered CLAUDE.md</td><td>Root file for overview, subfolder files for specific guidelines</td></tr><tr><td>Specs Folder</td><td>Reference specifications directly with @specs/filename.md</td></tr><tr><td>Clear Separation</td><td>Frontend and backend code in separate folders, easy to navigate</td></tr></table>

# Phase III:Todo AI Chatbot

Basic Level Functionality

Objective: Create an AI-powered chatbot interface for managing todos through natural language using MCP (Model Context Protocol) server architecture and using Claude Code and Spec-Kit Plus.

# Requirements

1. Implement conversational interface for all Basic Level features  
2. Use OpenAI Agents SDK for AI logic  
3. Build MCP server with Official MCP SDK that exposes task operations as tools  
4. Stateless chat endpoint that persists conversation state to database  
5. AI agents use MCP tools to manage tasks. The MCP tools will also be stateless and will store state in the database.

# Technology Stack

<table><tr><td>Component</td><td>Technology</td></tr><tr><td>Frontend</td><td>OpenAI ChatKit</td></tr><tr><td>Backend</td><td>Python FastAPI</td></tr><tr><td>AI Framework</td><td>OpenAI Agents SDK</td></tr><tr><td>MCP Server</td><td>Official MCP SDK</td></tr><tr><td>ORM</td><td>SQLModel</td></tr><tr><td>Database</td><td>Neon Serverless PostgreSQL</td></tr><tr><td>Authentication</td><td>Better Auth</td></tr></table>

# Architecture

![](images/e9695ab551db5495ad2f9d48fff3876b27023b9aebe0575b2b4a8f6949bd26e7.jpg)

![](images/f82584bbc83c40294fac6415cd4d745ce88091babff00e924adb7abef92870cb.jpg)

# Database Models

<table><tr><td>Model</td><td>Fields</td><td>Description</td></tr><tr><td>Task</td><td>user_id, id, title, description, completed, created_at, updated_at</td><td>Todo items</td></tr><tr><td>Conversation</td><td>user_id, id, created_at, updated_at</td><td>Chat session</td></tr><tr><td>Message</td><td>user_id, id, conversation_id, role (user/assistant), content, created_at</td><td>Chat history</td></tr></table>

# Chat API Endpoint

<table><tr><td>Method</td><td>Endpoint</td><td>Description</td></tr><tr><td>POST</td><td>/api/{user_id}/chat</td><td>Send message &amp; get AI response</td></tr></table>

# Request

<table><tr><td>Field</td><td>Type</td><td>Required</td><td>Description</td></tr><tr><td>conversation_id</td><td>integer</td><td>No</td><td>Existing conversation ID (creates new if not provided)</td></tr><tr><td>message</td><td>string</td><td>Yes</td><td>User&#x27;s natural language message</td></tr></table>

# Response

<table><tr><td>Field</td><td>Type</td><td>Description</td></tr><tr><td>conversation_id</td><td>integer</td><td>The conversation ID</td></tr><tr><td>response</td><td>string</td><td>AI assistant&#x27;s response</td></tr><tr><td>tool_calls</td><td>array</td><td>List of MCP tools invoked</td></tr></table>

# MCP Tools Specification

The MCP server must expose the following tools for the AI agent:

# Tool: add_task

<table><tr><td>Purpose</td><td>Create a new task</td></tr><tr><td>Parameters</td><td>user_id (string, required), title (string, required), description (string, optional)</td></tr><tr><td>Returns</td><td>task_id, status, title</td></tr><tr><td>Example Input</td><td>{&quot;user_id&quot;: &quot;ziakhan&quot;, &quot;title&quot;: &quot;Buy groceries&quot;, &quot;description&quot;: &quot;Milk, eggs, bread&quot;}</td></tr></table>

Example Output {"task_id": 5, "status": "created", "title": "Buy groceries"}

# Tool: list_tasks

<table><tr><td>Purpose</td><td>Retrieve tasks from the list</td></tr><tr><td>Parameters</td><td>status (string, optional: &quot;all&quot;, &quot;pending&quot;, &quot;completed&quot;)</td></tr><tr><td>Returns</td><td>Array of task objects</td></tr><tr><td>Example Input</td><td>{user_id (string, required), &quot;status&quot;: &quot;pending&quot;}</td></tr><tr><td>Example Output</td><td>[{ &quot;id&quot;: 1, &quot;title&quot;: &quot;Buy groceries&quot;, &quot;completed&quot;: false}, ... ]</td></tr></table>

# Tool: complete_task

<table><tr><td>Purpose</td><td>Mark a task as complete</td></tr><tr><td>Parameters</td><td>user_id (string, required), task_id (integer, required)</td></tr><tr><td>Returns</td><td>task_id, status, title</td></tr><tr><td>Example Input</td><td>{&quot;user_id&quot;: &quot;ziakhan&quot;, &quot;task_id&quot;: 3}</td></tr><tr><td>Example Output</td><td>{&quot;task_id&quot;: 3, &quot;status&quot;: &quot;completed&quot;, &quot;title&quot;: &quot;Call mom&quot;}</td></tr></table>

# Tool: delete_task

<table><tr><td>Purpose</td><td>Remove a task from the list</td></tr><tr><td>Parameters</td><td>user_id (string, required), task_id (integer, required)</td></tr><tr><td>Returns</td><td>task_id, status, title</td></tr><tr><td>Example Input</td><td>{&quot;user_id&quot;: &quot;ziakhan&quot;, &quot;task_id&quot;: 2}</td></tr><tr><td>Example Output</td><td>{&quot;task_id&quot;: 2, &quot;status&quot;: &quot;deleted&quot;, &quot;title&quot;: &quot;Old task&quot;}</td></tr></table>

# Tool: update_task

<table><tr><td>Purpose</td><td>Modify task title or description</td></tr><tr><td>Parameters</td><td>user_id (string, required), task_id (integer, required), title (string, optional), description (string, optional)</td></tr><tr><td>Returns</td><td>task_id, status, title</td></tr><tr><td>Example Input</td><td>{&quot;user_id&quot;: &quot;ziakhan&quot;, &quot;task_id&quot;: 1, &quot;title&quot;: &quot;Buy groceries and fruits&quot;}</td></tr><tr><td>Example Output</td><td>{&quot;task_id&quot;: 1, &quot;status&quot;: &quot;updated&quot;, &quot;title&quot;: &quot;Buy groceries and fruits&quot;}</td></tr></table>

# Agent Behavior Specification

<table><tr><td>Behavior</td><td>Description</td></tr><tr><td>Task Creation</td><td>When user mentions adding/creating/remembering something, use add_task</td></tr><tr><td>Task Listing</td><td>When user asks to see/show/list tasks, use list_tasks with appropriate filter</td></tr><tr><td>Task Completion</td><td>When user says done/complete/finished, use complete_task</td></tr><tr><td>Task Deletion</td><td>When user says delete/remove/cancel, use delete_task</td></tr><tr><td>Task Update</td><td>When user says change/update/rename, use update_task</td></tr><tr><td>Confirmation</td><td>Always confirm actions with friendly response</td></tr><tr><td>Error Handling</td><td>Gracefully handle task not found and other errors</td></tr></table>

# Conversation Flow (Stateless Request Cycle)

1. Receive user message  
2. Fetch conversation history from database  
3. Build message array for agent (history + new message)  
4. Store user message in database  
5. Run agent with MCP tools  
6. Agent invokes appropriate MCP tool(s)  
7. Store assistant response in database  
8. Return response to client  
9. Server holds NO state (ready for next request)

# Natural Language Commands

The chatbot should understand and respond to:

<table><tr><td>User Says</td><td>Agent Should</td></tr><tr><td>&quot;Add a task to buy groceries&quot;</td><td>Call add_task with title &quot;Buy groceries&quot;</td></tr><tr><td>&quot;Show me all my tasks&quot;</td><td>Call list_tasks with status &quot;all&quot;</td></tr><tr><td>&quot;What&#x27;s pending?&quot;</td><td>Call list_tasks with status &quot;pending&quot;</td></tr><tr><td>&quot;Mark task 3 as complete&quot;</td><td>Call complete_task with task_id 3</td></tr><tr><td>&quot;Delete the meeting task&quot;</td><td>Call list_tasks first, then delete_task</td></tr><tr><td>&quot;Change task 1 to &#x27;Call mom tonight&#x27;&quot;</td><td>Call update_task with new title</td></tr><tr><td>&quot;I need to remember to pay bills&quot;</td><td>Call add_task with title &quot;Pay bills&quot;</td></tr><tr><td>&quot;What have I completed?&quot;</td><td>Call list_tasks with status &quot;completed&quot;</td></tr></table>

# Deliverables

1. GitHub repository with:

- /frontend - ChatKit-based UI  
- /frontend - FastAPI + Agents SDK + MCP  
- /specs - Specification files for agent and MCP tools  
- Database migration scripts  
- README with setup instructions

2. Working chatbot that can:

- Manage tasks through natural language via MCP tools  
- Maintain conversation context via database (stateless server)  
- Provide helpful responses with action confirmations  
- Handle errors gracefully  
- Resume conversations after server restart

# Key Architecture Benefits

<table><tr><td>Aspect</td><td>Benefit</td></tr><tr><td>MCP Tools</td><td>Standardized interface for AI to interact with your app</td></tr><tr><td>Single Endpoint</td><td>Simpler API — AI handles routing to tools</td></tr><tr><td>Stateless Server</td><td>Scalable, resilient, horizontally scalable</td></tr><tr><td>Tool Composition</td><td>Agent can chain multiple tools in one turn</td></tr></table>

# Key Stateless Architecture Benefits

- Scalability: Any server instance can handle any request  
- Resilience: Server restarts don't lose conversation state  
Horizontal scaling: Load balancer can route to any backend  
- Testability: Each request is independent and reproducible

# Phase IV: Local Kubernetes Deployment (Minikube, Helm Charts, kubectl-ai, Kagent, Docker Desktop, and Gordon)

Cloud Native Todo Chatbot with Basic Level Functionality

Objective: Deploy the Todo Chatbot on a local Kubernetes cluster using Minikube, Helm Charts.

# Requirements

- Containerize frontend and backend applications (Use Gordon)  
Use Docker AI Agent (Gordon) for AI-assisted Docker operations  
- Create Helm charts for deployment (Use kubectl-ai and/or kagent to generate)  
- Use kubectl-ai and kagent for AI-assisted Kubernetes operations  
- Deploy on Minikube locally

Note: If Docker AI (Gordon) is unavailable in your region or tier, use standard Docker CLI commands or ask Claude Code to generate the docker run commands for you.

Technology Stack  

<table><tr><td>Component</td><td>Technology</td></tr><tr><td>Containerization</td><td>Docker (Docker Desktop)</td></tr><tr><td>Docker AI</td><td>Docker AI Agent (Gordon)</td></tr><tr><td>Orchestration</td><td>Kubernetes (Minikube)</td></tr><tr><td>Package Manager</td><td>Helm Charts</td></tr><tr><td>AI DevOps</td><td>kubectl-ai, and Kagent</td></tr><tr><td>Application</td><td>Phase III Todo Chatbot</td></tr></table>

# AIOps

Use Docker AI Agent (Gordon) for intelligent Docker operations:

```txt
To know its capabilities docker ai "What can you do?"
```

Enable Gordon: Install latest Docker Desktop 4.53+, go to Settings > Beta features, and toggle it on.

Use kubectl.ai, and Kagent for intelligent Kubernetes operations:

```shell
# Using kubectl-ai  
kubectl-ai "deploy the todo frontend with 2 replicas"  
kubectl-ai "scale the backend to handle more load"  
kubectl-ai "check why the pods are failing"
```

```txt
Using kagent  
kagent "analyze the cluster health"  
kagent "optimize resource allocation"
```

Starting with kubectl-ai will make you feel empowered from day one. Layer in Kagent for advanced use cases. Pair them with Minikube for zero-cost learning and work.

# Research Note: Using Blueprints for Spec-Driven Deployment

Can Spec-Driven Development be used for infrastructure automation, and how we may need to use blueprints powered by Claude Code Agent Skills.

1. Is Spec-Driven Development Key for Infrastructure Automation?  
2. ChatGPT Progressive Learning Conversation  
3. Spec-Driven Cloud-Native Architecture: Governing AI Agents for Managed Services with Claude Code and SpecKit

# Phase V: Advanced Cloud Deployment

Advanced Level Functionality on DigitalOcean Kubernetes

Objective: Implement advanced features and deploy first on Minikube locally and then to production-grade Kubernetes on DigitalOcean and Kafka on Redpanda Cloud.

# Part A: Advanced Features

- Implement all Advanced Level features (Recurring Tasks, Due Dates & Reminders)  
- Implement Intermediate Level features (Priorities, Tags, Search, Filter, Sort)  
- Add event-driven architecture with Kafka  
- Implement Dapr for distributed application runtime

# Part B: Local Deployment

Deploy to Minikube  
- Deploy Dapr on Minikube use Full Dapr: Pub/Sub, State, Bindings (cron), Secrets, Service Invocation

# Part C: Cloud Deployment

- Deploy to DigitalOcean Kubernetes (DOKS)  
- Deploy Dapr on DOKS use Full Dapr: Pub/Sub, State, Bindings (cron), Secrets, Service Invocation  
Use Kafka on Redpanda Cloud  
- Set up CI/CD pipeline using Github Actions  
- Configure monitoring and logging

# DigitalOcean Setup

New DigitalOcean accounts receive $200 credit for 60 days:

1. Sign up at digitalOcean.com  
2. Create a Kubernetes cluster (DOKS)  
3. Configure kubectl to connect to DOKS  
4. Deploy using Helm charts from Phase IV

# Kafka Use Cases in Phase

Event-Driven Architecture for Todo Chatbot

# 1. Reminder/Notification System

![](images/17ade19f09d4fc593267a459d5ea38ef9ed2663e80f5813f8a891ffe9e73ea27.jpg)

When a task with a due date is created, publish a reminder event. A separate notification service consumes and sends reminders at the right time.

# 2. Recurring Task Engine

![](images/02d017aef9e656927485279a69e090ab6dffcd9f09fe41d560ece4378abd0847.jpg)

When a recurring task is marked complete, publish an event. A separate service consumes it and auto-creates the next occurrence.

# 3. Activity/Audit Log

![](images/8b247f519cb9730e091232acf77ff7a65d7896b3ecdd0df57ed913f49b86e250.jpg)

Every task operation (create, update, delete, complete) publishes to Kafka. An audit service consumes and maintains a complete history.

# 4. Real-time Sync Across Clients

![](images/29b539ee8a038e559006857da191edde03c84264744c511f111f9c1126091784.jpg)

Changes from one client are broadcast to all connected clients in real-time.

# Recommended Architecture

![](images/9c700008d3d90a13059e0169adee29d8c6c6c1d9a1b4b2a9959797598e5ad9a3.jpg)

![](images/028b3a99e18826ec3a5c48fc04da53fdc1d03b4d796d3e7bccef22a7c4030fc4.jpg)

# Kafka Topics

<table><tr><td>Topic</td><td>Producer</td><td>Consumer</td><td>Purpose</td></tr><tr><td>task-events</td><td>Chat API (MCP Tools)</td><td>Recurring Task Service, Audit Service</td><td>All task CRUD operations</td></tr><tr><td>reminders</td><td>Chat API (when due date set)</td><td>Notification Service</td><td>Scheduled reminder triggers</td></tr><tr><td>task-updates</td><td>Chat API</td><td>WebSocket Service</td><td>Real-time client sync</td></tr></table>

# Event Schema Examples

# Task Event

<table><tr><td>Field</td><td>Type</td><td>Description</td></tr><tr><td>event_type</td><td>string</td><td>&quot;created&quot;, &quot;updated&quot;, &quot;completed&quot;, &quot;deleted&quot;</td></tr><tr><td>task_id</td><td>integer</td><td>The task ID</td></tr><tr><td>task_data</td><td>object</td><td>Full task object</td></tr><tr><td>user_id</td><td>string</td><td>User who performed action</td></tr><tr><td>timestamp</td><td>datetime</td><td>When event occurred</td></tr></table>

# Reminder Event

<table><tr><td>Field</td><td>Type</td><td>Description</td></tr><tr><td>task_id</td><td>integer</td><td>The task ID</td></tr><tr><td>title</td><td>string</td><td>Task title for notification</td></tr><tr><td>due_at</td><td>datetime</td><td>When task is due</td></tr><tr><td>remind_at</td><td>datetime</td><td>When to send reminder</td></tr><tr><td>user_id</td><td>string</td><td>User to notify</td></tr></table>

# Why Kafka for Todo App?

<table><tr><td>Without Kafka</td><td>With Kafka</td></tr><tr><td>Reminder logic coupled with main app</td><td>Decoupled notification service</td></tr><tr><td>Recurring tasks processed synchronously</td><td>Async processing, no blocking</td></tr><tr><td>No activity history</td><td>Complete audit trail</td></tr><tr><td>Single client updates</td><td>Real-time multi-client sync</td></tr><tr><td>Tight coupling between services</td><td>Loose coupling, scalable</td></tr></table>

# Bottom Line

Kafka turns the Todo app from a simple CRUD app into an event-driven system where services communicate through events rather than direct API calls. This is essential for the advanced features (recurring tasks, reminders) and scales better in production.

# Key Takeaway:

Kafka enables decoupled, scalable microservices architecture where the Chat API publishes events and specialized services (Notification, Recurring Task, Audit) consume and process them independently.

# Kafka Service Recommendations

# For Cloud Deployment

<table><tr><td>Service</td><td>Free Tier</td><td>Pros</td><td>Cons</td></tr><tr><td>Redpanda Cloud</td><td>Free Serverless tier</td><td>Kafka-compatible, no Zookeeper, fast, easy setup</td><td>Newer ecosystem</td></tr><tr><td>Confluent Cloud</td><td>$400 credit for 30 days</td><td>Industry standard, Schema Registry, great docs</td><td>Credit expires</td></tr><tr><td>CloudKarafka</td><td>&quot;Developer Duck&quot; free plan</td><td>Simple, 5 topics free</td><td>Limited throughput</td></tr><tr><td>Aiven</td><td>$300 credit trial</td><td>Fully managed, multi-cloud</td><td>Trial expires</td></tr><tr><td>Self-hosted (Strimzi)</td><td>Free (just compute cost)</td><td>Full control, learning experience</td><td>More complex setup</td></tr></table>

# For Local Development (Minikube)

<table><tr><td>Option</td><td>Complexity</td><td>Description</td></tr><tr><td>Redpanda (Docker) ★</td><td>Easy</td><td>Single binary, no Zookeeper, Kafka-compatible</td></tr><tr><td>Bitnami Kafka Helm</td><td>Medium</td><td>Kubernetes-native, Helm chart</td></tr><tr><td>Strimzi Operator</td><td>Medium-Hard</td><td>Production-grade K8s operator</td></tr></table>

# Primary Recommendation: Redpanda Cloud (Serverless)

Best for hackathon because:

Free serverless tier (no credit card for basic usage)  
- Kafka-compatible - same APIs, clients work unchanged  
- No Zookeeper - simpler architecture  
- Fast setup - under 5 minutes  
- REST API + Native protocols

Sign up: https://redpanda.com/cloud

For Local/Minikube: Redpanda Docker

Single container, Kafka-compatible:  
```yaml
docker-compose.redpanda.yml  
services:  
redpanda:  
    image: redpandadata/redpanda:latest  
command:  
    - redpanda start  
    --smp 1  
    --memory 512M  
    --overprovisioned  
    --kafka-addr PLAINTEXT://0.0.0.0:9092  
    --advertise-kafka-addr PLAINTEXT://localhost:9092  
ports:  
    - "9092:9092"  
    - "8081:8081" # Schema Registry  
    - "8082:8082" # REST Proxy
```

# Alternative: Self-Hosted on Kubernetes (Strimzi)

Good learning experience for students:  
```shell
Install Strimzi operator  
kubectl create namespace kafka  
kubectl apply -f https://strimzi.io/install/latest?namespace=kafka  
# Create Kafka cluster  
kubectl apply -f kafka-cluster.yaml
```

Redpanda Cloud Quick Setup  
```txt
Step Action  
1 Sign up at redpanda.com/cloud  
2 Create a Serverless cluster (free tier)  
3 Create topics: task-events, reminders, task-updates  
4 Copy bootstrap server URL and credentials  
5 Use standard Kafka clients (kafkapython, aiokafka)
```

# Python Client Example

Standard kafkapython works with Redpanda:  
```python
from kafka import KafkaProducer   
import json   
producer  $=$  KafkaProducer( bootstrap_servers  $\coloneqq$  "YOUR-CLUSTER.cloud.redpanda.com:9092", security_protocol  $\coloneqq$  "SASL_SSL", SASl_mechanism  $\coloneqq$  "SCRAM-SHA-256", SASl plainlyUsername  $\coloneqq$  "YOUR-USERNAME", SASl plainly_password  $\coloneqq$  "YOUR-PASSWORD", value垦erizer  $\coloneqq$  lambda v: json.dumps(v).encode('utf-8')   
#Publish event producer.send("task-events","event_type": "created", "task_id":1)}
```

Summary for Hackathon  
```txt
Type Recommendation Local: Minikube Redpanda Docker container
```

<table><tr><td>Type</td><td>Recommendation</td></tr><tr><td>Cloud</td><td>Redpanda Cloud Serverless (free) or Strimzi self-hosted</td></tr></table>

# Dapr Integration Guide

# What is Dapr?

Dapr (Distributed Application Runtime) is a portable, event-driven runtime that simplifies building microservices. It runs as a sidecar next to your application and provides building blocks via HTTP/gRPC APIs.

# Dapr Building Blocks for Todo App

<table><tr><td>Building Block</td><td>Use Case in Todo App</td></tr><tr><td>Pub/Sub</td><td>Kafka abstraction – publish/subscribe without Kafka client code</td></tr><tr><td>State Management</td><td>Conversation state storage (alternative to direct DB calls)</td></tr><tr><td>Service Invocation</td><td>Frontend → Backend communication with built-in retries</td></tr><tr><td>bindings</td><td>Cron triggers for scheduled reminders</td></tr><tr><td>Secrets Management</td><td>Store API keys, DB credentials securely</td></tr></table>

# Architecture: Without Dapr vs With Dapr

# Without Dapr (Direct Dependencies)

![](images/e8e96a7aa0b4cd54d38c357c8338d825912f49482448631f8f1932ab35f55875.jpg)

# With Dapr (Abstracted Dependencies)

![](images/11d2e743ff3b512d5c8757fe2db6cfd323f6549148652420c4950921c417b1fb.jpg)

# Use Case 1: Pub/Sub (Kafka Abstraction)

Instead of using kafkapython directly, publish events via Dapr:

# Without Dapr:

```python
from kappa import KafkaProducer  
producer = KafkaProducer(bootstrap_servers="kafka:9092", ...)  
producer.send("task-events", value=event)
```

# With Dapr:

```txt
import httpx   
#Publish via Dapr sidecar (no Kafka library needed!) await httpx.post( "http://localhost:3500/v1.0/publish/kafka-pubsub/task-events", json  $=$  {"event_type": "created", "task_id": 1}
```

# Dapr Component Configuration:

```yaml
apiVersion: dapr.io/v1alpha1  
kind: Component  
metadata:  
    name: kafka-pubsub  
spec:  
    type: pubsub.kafka  
version: v1  
metadata:  
    - name: brokers  
        value: "kafka:9092"  
    - name: consumerGroup  
        value: "todo-service"
```

# Use Case 2: State Management (Conversation State)

Store conversation history without direct DB code:

# Without Dapr:

```python
from sqlmodel import Session  
session.add(Message ...)  
session.commit()
```

# With Dapr:

```txt
import httpx   
# Save state via Dapr await httpx.post( "http://localhost:3500/v1.0/state/statestore", json  $= \left\{\right.$  "key":f"conversation-{conv_id}", "value": {"messages": messages} }   
）   
#Get state response  $=$  await httpx.get( f"http://localhost:3500/v1.0/state/statestore/conversation-{conv_id}"
```

# Dapr Component Configuration:

```yaml
apiVersion: dapr.io/v1alpha1  
kind: Component  
metadata:  
    name: statestore  
spec:  
    type: state.postgresql
```

```txt
version: v1  
metadata:  
    - name: connectionString  
        value: "host=neon.db user=... password=... dbname=todo"
```

# Use Case 3: Service Invocation (Frontend  $\rightarrow$  Backend)

Built-in service discovery, retries, and mTLS:

# Without Dapr:

```javascript
// Frontend must know backend URL  
fetch("http://frontend-service:8000/api/chat", {...})
```

# With Dapr:

```txt
// Frontend calls via Dapr sidecar - automatic discovery  
fetch("http://localhost:3500/v1.0/invoke/forum-service/method/api/chat", {...})
```

# Use Case 4: Input Bindings (Scheduled Reminders)

Trigger reminder checks on a schedule:

# Dapr Cron Binding:

```yaml
apiVersion: dapr.io/v1alpha1  
kind: Component  
metadata:  
    name: reminder-cron  
spec:  
    type: bindings.cron  
    version: v1  
    metadata:  
        - name: schedule  
            value: "/5 * * * *" # Every 5 minutes
```

# Backend Handler:

```txt
@app.post("/reminder-cron")  
async def check reminders():  
    # Dapr calls this every 5 minutes  
    # Check for due tasks and send notifications pass
```

# Use Case 5: Secrets Management

Securely store and access credentials:

# Dapr Component (Kubernetes Secrets):

```yaml
apiVersion: dapr.io/v1alpha1  
kind: Component  
metadata:  
    name: kubernetes-secrets  
spec:  
    type: secretstores.kubernetes  
version: v1
```

# Access in App:

```txt
import httpx   
response  $=$  await httpx.get( "http://localhost:3500/v1.0/secrets/kubernetes-secrets/openai-api-key" ) api_key  $\equiv$  response.json()["openai-api-key"]
```

# Complete Dapr Architecture

![](images/e6c5dca976f5d50f404e94a1126d9d8bdd761f91b0b74c0a2d1a8e04ec6b0b6a.jpg)

# Dapr Components Summary

<table><tr><td>Component</td><td>Type</td><td>Purpose</td></tr><tr><td>kafka-pubsub</td><td>pubsub.kafka</td><td>Event streaming (task-events, reminders)</td></tr><tr><td>statestore</td><td>state.postgresql</td><td>Conversation state, task cache</td></tr><tr><td>reminder-cron</td><td>connections.cron</td><td>Trigger reminder checks</td></tr><tr><td>kubernetes-secrets</td><td>secretstores.kubernetes</td><td>API keys, DB credentials</td></tr></table>

# Why Use Dapr?

<table><tr><td>Without Dapr</td><td>With Dapr</td></tr><tr><td>Import Kafka, Redis, Postgres libraries</td><td>Single HTTP API for all</td></tr><tr><td>Connection strings in code</td><td>Dapr components (YAML config)</td></tr><tr><td>Manual retry logic</td><td>Built-in retries, circuit breakers</td></tr><tr><td>Service URLs hardcoded</td><td>Automatic service discovery</td></tr><tr><td>Secrets in env vars</td><td>Secure secret store integration</td></tr><tr><td>Vendor lock-in</td><td>Swap Kafka for RabbitMQ with config change</td></tr></table>

# Local vs Cloud Dapr Usage

<table><tr><td>Phase</td><td>Dapr Usage</td></tr><tr><td>Local (Minikube)</td><td>Install Dapr, use Pub/Sub for Kafka, basic state management</td></tr><tr><td>Cloud (DigitalOcean)</td><td>Full Dapr: Pub/Sub, State, Bindings (cron), Secrets, Service Invocation</td></tr></table>

# Getting Started with Dapr

```shell
# Install Dapr CLI  
curl -fsLS https://raw.githubusercontent.com/dapr/cli/master/install/install.sh | bash  
# Initialize Dapr on Kubernetes  
dapr init -k  
# Deploy components  
kubectl apply -f dapr-components/  
# Run app with Dapr sidecar  
dapr run --app-id backend --app-port 8000 -- uvicorn main:app
```

# Bottom Line

Dapr abstracts infrastructure (Kafka, DB, Secrets) behind simple HTTP APIs. Your app code stays clean, and you can swap backends (e.g., Kafka  $\rightarrow$  RabbitMQ) by changing YAML config, not code.

# Submission Requirements

# Required Submissions

1. Public GitHub Repository containing:  
- All source code for all completed phases  
- /specs folder with all specification files  
CLAUDE.md with Claude Code instructions  
- README.md with comprehensive documentation  
- Clear folder structure for each phase

2. Deployed Application Links:

- Phase II: Vercel/frontend URL + Backend API URL  
- Phase III-V: Chatbot URL  
- Phase IV: Instructions for local Minikube setup  
Phase V: DigitalOcean deployment URL

3. Demo Video (maximum 90 seconds):

- Demonstrate all implemented features  
Show spec-driven development workflow  
Judges will only watch the first 90 seconds  
4. WhatsApp Number for presentation invitation

# Resources

Core Tools  

<table><tr><td>Tool</td><td>Link</td><td>Description</td></tr><tr><td>Claude Code</td><td>claude.com/product/claude-code</td><td>AI coding assistant</td></tr><tr><td>GitHub Spec-Kit</td><td>github.com/panaversity/spec-kit-plus</td><td>Specification management</td></tr><tr><td>OpenAI ChatKit</td><td>platform.openai.com/docs/guides/chatkit</td><td>Chatbot UI framework</td></tr><tr><td>MCP</td><td>github.com/modelcontextprotocol/python-sdk</td><td>MCP server framework</td></tr></table>

Infrastructure  

<table><tr><td>Service</td><td>Link</td><td>Notes</td></tr><tr><td>Neon DB</td><td>neon.tech</td><td>Free tier available</td></tr><tr><td>Vercel</td><td>vercel.com</td><td>Free frontend hosting</td></tr><tr><td>DigitalOcean</td><td>digitalOcean.com</td><td>$200 credit for 60 days</td></tr><tr><td>Minikube</td><td>minikube.sigs.k8s.io</td><td>Local Kubernetes</td></tr></table>

# Frequently Asked Questions

# Q: Can I skip phases?

A: No, each phase builds on the previous. You must complete them in order.

# Q: Can I use different technologies?

A: The core stack must remain as specified. You can add additional tools/libraries.

# Q: Do I need a DigitalOcean account from the start?

A: No, only for Phase V. Use the $200 free credit for new accounts.

# Q: Can I work in a team?

A: This is an individual hackathon. Each participant submits separately.

# Q: What if I don't complete all the phases?

A: Submit what you complete. Partial submissions are evaluated proportionally.

# Good luck, and may your specs be clear and your code be clean!

![](images/a7dcf3c3b06a26acfa8502a5b34f9380ac71b33e7cbc7ebc5d6c026012166af3.jpg)

The Panaversity, PIAIC, and GIAIC Teams
